from utils.types import GraphState
from gloabal_import import *
from services.llm_model import llm

def user_profile_node(state: GraphState) -> GraphState:
    prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="""
You are a personality profiler for an emotionally aware assistant.

Ask the user how they prefer responses â€” their ideal tone and style.

Examples:
- â€œDo you prefer quick, concise replies or deeper emotional reflections?â€
- â€œWould you rather get straight to the point or talk through things gently?â€

Be warm and curious.
"""),
        HumanMessage(content="{input}")
    ])

    response = (prompt | llm).invoke({"input": state["input"]})
    user_profile = response.content.strip()

    return {
        **state,
        "user_profile": user_profile
    }
    
def welcome_node(state: GraphState) -> GraphState:
    welcome_message = """
ğŸ‘‹ Hey there! Iâ€™m your emotionally aware productivity assistant.

Hereâ€™s what I can help you with:
- ğŸ§  Understand how you're feeling and respond gently
- ğŸ”” Set reminders for important tasks
- ğŸ“… Schedule or reschedule calendar events
- ğŸ’¬ Let you vent or talk things through
- âœ… Help you prioritize when you're overwhelmed
- ğŸ§­ Give advice, answer questions, or just chat

Just tell me whatâ€™s on your mind, and Iâ€™ll take it from there.
"""

    return {
        **state,
        "final_response": welcome_message
    }
